---
title: "PAF"
author: "Di"
date: "2023-08-08"
output: html_document
---

```{r setup, include=FALSE}
#library(epiR)
library(graphPAF)
#library(paf)
library(boot)
library(psych)
library(polycor)

```

```{r}
# Example data
# df = HW8_NOAA_10degree_1D_updated0615
# hr <- HW10_fully_adjusted$estimate[1]; hr
# 
# head(df)

getWeightedPAF = function(df, hr){
    data_matrix <- df %>% select(hwd.ind, trueage, sex, #UorR, co.resi.baseline, marital.baseline, 
                                 ndvi.scale, pm25.scale, rh.scale, # education, occupation
                                 adl.status, iadl.status, mmse.status.baseline)%>%mutate_all(~ as.numeric(factor(.)))
                                 #life.sat.score, personality.score, 
                                 #fruit, veg, tea, d71, d81, d91,
                                 #high.invol.act,f113.code) %>%
    
    pca_cor<-hetcor(data_matrix,ML=TRUE)
     
    # step3. conduct a PCA on the correlation matrix to generate eigenvectors
    my_pca <- princomp(pca_cor, n.comp = sum(my_pca$sdev^2 >= 1))
     
    # screen plot to find the elbow
    eig_df <- data.frame(Comp = 1:length(my_pca$sdev), Eigenvalue = my_pca$sdev^2)
    # Plot the scree plot
    # ggplot(eig_df, aes(x = Comp, y = Eigenvalue)) +
    #   geom_point(size = 3, color = "red") +
    #   geom_line(size = 1.2, color = "blue") +
    #   xlab("Component") +
    #   ylab("Eigenvalue") +
    #   ggtitle("Scree Plot")
     
    # the 'elbow' in this example is 2
     
    # step4. retain components with eighvalues â‰¥1 in the model. Then communality can be calculated as the sum of the square of all factor loadings
    my_loadings<-my_pca$loadings
    my_communality<-rowSums(my_loadings[,1:2]^2)



    # number of events occurred among the group exposed/unexposed to heatwave
    df %>% filter(event.death == 1 & hwd.ind == 1) %>% summarise(event.exposed = n()) -> event.exposed; event.exposed = as.numeric(event.exposed)
    df %>% filter(event.death == 1 & hwd.ind == 0) %>% summarise(event.unexposed = n()) -> event.unexposed; event.unexposed = as.numeric(event.unexposed)
    
    #  the amount of person time while being exposed/unexposed to a particular risk 
    df %>% filter(hwd.ind == 1) %>% summarise(pt.exposed = n()) -> pt.exposed; pt.exposed = as.numeric(pt.exposed)
    df %>% filter(hwd.ind == 0) %>% summarise(pt.unexposed = n()) -> pt.unexposed; pt.unexposed = as.numeric(pt.unexposed)
    
    
    # Calculate incidence rates
    ir_exposed <- event.exposed / pt.exposed
    ir_unexposed <- event.unexposed / pt.unexposed
    
    # Calculate Attributable Fraction
    af <- (ir_exposed - ir_unexposed) / ir_exposed
    
    # Calculate Population Attributable Fraction
    paf <- (af * hr) / (1 + af * (hr - 1))
    
    
    adjusted_af <- af * my_communality[1]  # Adjust for communality
    adjusted_paf <- (adjusted_af * hr) / (1 + adjusted_af * (hr - 1))
    # Print the calculated PAF
    cat("Population Attributable Fraction (PAF) using HR:", adjusted_paf, "\n")
    
    
    # Define a function to calculate PAF
    calculate_paf <- function(data, indices, hr) {
    
        event.exposed <- sum(data$event.death[indices] == 1 & data$hwd.ind[indices] == 1)
        event.unexposed <- sum(data$event.death[indices] == 1 & data$hwd.ind[indices] == 0)
        pt.exposed <- sum(data$hwd.ind[indices] == 1)
        pt.unexposed <- sum(data$hwd.ind[indices] == 0)
        
        ir_exposed <- event.exposed / pt.exposed
        ir_unexposed <- event.unexposed / pt.unexposed
        af <- (ir_exposed - ir_unexposed) / ir_exposed
        adjusted_af <- af * my_communality[1]  # Adjust for communality
        adjusted_paf <- (adjusted_af * hr) / (1 + adjusted_af * (hr - 1))
        
        
    return(adjusted_paf)
    }




    # Set the number of bootstrap replicates
    n_replicates <- 100
    
    # Perform bootstrap and calculate CI for PAF
    boot_results <- boot(data = df, statistic = calculate_paf, R = n_replicates, hr = hr)
    
    # Calculate the confidence interval using basic method
    ci <- boot.ci(boot_results, type = "basic", conf = 0.95)
    
    print(ci)
    
}

getWeightedPAF(HW9_NOAA_10degree_2D_updated0615, HW9_fully_adjusted$estimate[1])
#getWeightedPAF(HW8_NOAA_10degree_1D_updated0615, HW8_fully_adjusted$estimate[1])
getWeightedPAF(HW7_WMO_95th_3D_updated0615, HW7_fully_adjusted$estimate[1])
getWeightedPAF(HW6_WMO_95th_2D_updated0615, HW6_fully_adjusted$estimate[1])
getWeightedPAF(HW5_WMO_95th_1D_updated0615, HW5_fully_adjusted$estimate[1])
getWeightedPAF(HW4_WMO_90th_3D_updated0615, HW4_fully_adjusted$estimate[1])
getWeightedPAF(HW3_WMO_90th_2D_updated0615, HW3_fully_adjusted$estimate[1])
getWeightedPAF(HW2_WMO_90th_1D_updated0615, HW2_fully_adjusted$estimate[1])
getWeightedPAF(HW1_CMA_updated0615, HW1_fully_adjusted$estimate[1])

```






```{R}
def= 'HW8'
covariates <- c(#demographic
                    "agegroup", "sex", "UorR", "co.resi.baseline","education", "occupation", "marital.baseline",
                    # physcialand mental disorder
                    "adl.status", "mmse.status.baseline", "iadl.status",
                    # section b
                    "satisfaction_tertiles", "personality_tertiles",
                    # life style
                    "fruit", "veg", "tea", "d71", "d81", "d91",
                    # social
                    "involvement_tertiles", "network.interact"
                    )

HW8_NOAA_10degree_1D_updated0615 -> df

event.exposed.list <- list()
pca_results_list = list()
communalities.list = list()

for (covariate in covariates) {
    
    
    df %>% group_by_at(covariate) %>% filter(event.death == 1 & hwd.ind == 1) %>% summarise(event.exposed = n()) -> event.exposed
    df %>% group_by_at(covariate) %>% filter(event.death == 1 & hwd.ind == 0) %>% summarise(event.unexposed = n()) -> event.unexposed
    colnames(event.exposed) = c('var.level', 'event.exposed')
    colnames(event.unexposed) = c('var.level', 'event.unexposed')
    
    df %>% group_by_at(covariate) %>% filter(hwd.ind == 1) %>% summarise(pt.exposed = n()) -> pt.exposed; 
    df %>% group_by_at(covariate) %>% filter(hwd.ind == 0) %>% summarise(pt.unexposed = n()) -> pt.unexposed; 
    colnames(pt.exposed) = c('var.level', 'pt.exposed')
    colnames(pt.unexposed) = c('var.level', 'pt.unexposed')
    
    
    # Calculate incidence rates
    ir <- left_join(event.exposed, event.unexposed, by = 'var.level') %>% 
          left_join(pt.exposed, by = 'var.level') %>%
          left_join(pt.unexposed, by = 'var.level')
    
    ir %>% mutate(ir_exposed = event.exposed / pt.exposed,
                  ir_unexposed = event.unexposed / pt.unexposed,
                  # Calculate Attributable Fraction
                  af = ir_exposed - ir_unexposed) -> af

    
    # Calculate Population Attributable Fraction
    hr <- subgroup_HRs %>% filter(varname == covariate & definition == def) %>% select(varname, var.level, definition, HR.estimate)
    left_join(hr, af, by = 'var.level') %>% mutate(paf = (af * as.numeric(HR.estimate)) / (1 + af * (as.numeric(HR.estimate) - 1))) -> paf
    
    
    #paf <- (af * hr) / (1 + af * (hr - 1))
    
    
    ## ------ calculate communality ---------------- ##
    df %>% group_by_at(covariate) %>% select(hwd.ind, trueage, sex, co.resi.baseline,
                                              ndvi.scale, pm25.scale, rh.scale,
                                              adl.status, iadl.status, mmse.status.baseline) %>%
                                      mutate_all(~ as.numeric(factor(.))) -> data.matrix
                                        
    
    # Split the dataset by the levels of the covariate
  subset_list <- split(df, df[[covariate]])
  
  # Apply PCA to each subset
  pca_subset_list <- lapply(subset_list, function(subset_df) {
    # Select columns and convert to numeric factors as needed
    data_matrix <- subset_df %>%
      select(
        hwd.ind, trueage, sex, co.resi.baseline,
        ndvi.scale, pm25.scale, rh.scale,
        adl.status, iadl.status, mmse.status.baseline
      ) %>%
      mutate_all(~ as.numeric(factor(.)))
    
    # Perform PCA
    pca_cor <- hetcor(data_matrix, ML = TRUE)
    my_pca <- princomp(pca_cor, n.comp = sum(my_pca$sdev^2 >= 1))
    
    pca_results_list[[deparse(substitute(subset_df))]] <- my_pca
    
    # communality 
    my_loadings<-my_pca$loadings
    my_communality<-rowSums(my_loadings[,1:2]^2)[1]
    
    # Create an empty dataframe to store communalities
    communalities.df <- data.frame(covariate = character(0),
                                     level = character(0),
                                     communalities = numeric(0))
      
    communalities.list[[deparse(substitute(subset_df))]] <- my_communality  
  
  })
     
    # screen plot to find the elbow
    # eig_df <- data.frame(Comp = 1:length(my_pca$sdev), Eigenvalue = my_pca$sdev^2)

    
    
    
     # ## ------------- CI ---------------- ##
     #  # Set the number of bootstrap replicates
     #  n_replicates <- 100
     #  
     #  # Perform bootstrap and calculate CI for PAF
     #  boot_results <- boot(data = df, statistic = adjusted_paf, R = n_replicates, hr = hr)
     #  
     #  # Calculate the confidence interval using basic method
     #  ci <- boot.ci(boot_results, type = "basic", conf = 0.95)
  
}



    
    #### -------- adjusted PAF --------#### 
    adjusted_af <- af * my_communality[1]  # Adjust for communality
    adjusted_paf <- (adjusted_af * hr) / (1 + adjusted_af * (hr - 1))
    # Print the calculated PAF
    cat("Population Attributable Fraction (PAF) using HR:", adjusted_paf, "\n")
    
    
    #####  -------- CI ------------ ####
    # Set the number of bootstrap replicates
    n_replicates <- 100
    
    # Perform bootstrap and calculate CI for PAF
    boot_results <- boot(data = df, statistic = adjusted_paf, R = n_replicates, hr = hr)
    
    # Calculate the confidence interval using basic method
    ci <- boot.ci(boot_results, type = "basic", conf = 0.95)
    
    print(ci)
    
    return(adjusted_paf, ci)
    


getWeightedPAF(HW9_NOAA_10degree_2D_updated0615, HW9_fully_adjusted$estimate[1])


```



```{R}
# import subgroup HRs.xlsx directly as subgroup_HRs

```


```{r}
#getWeightedPAFsubgroups(HW8_NOAA_10degree_1D_updated0615, subgroup_HRs, agegroup)
df = HW8_NOAA_10degree_1D_updated0615
df = HW2_WMO_90th_1D_updated0615
hr.estimates = subgroup_HRs
stratify_var = 'agegroup'
def = 'HW2'


HW1_CMA_updated0615$sex = as.character(HW1_CMA_updated0615$sex)
class(HW1_CMA_updated0615$sex)

```

```{r function getSubPAF}


getSubPAF = function(df, def, stratify_var, hr.estimates){


      stratify_levels <- as.character(na.omit(unique(df[[stratify_var]])))
      stratify_levels <- stratify_levels[!(stratify_levels %in% c("don't know", "missing"))]#; stratify_levels
      
      
      
      df.paf = data.frame()
      #paf.df.list = list()
     
      for (level in stratify_levels) {
      
        subdf <- subset(df, df[[stratify_var]] == level)
        
        hr = hr.estimates$HR.estimate[which(hr.estimates$var.level == level &
                                            hr.estimates$varname == stratify_var &
                                            hr.estimates$definition == def)]
      
        if (stratify_var == 'sex') {
            
            data_matrix <- subdf %>% select(hwd.ind, trueage,
                                            ndvi.scale, pm25.scale, rh.scale, 
                                            adl.status, iadl.status, mmse.status.baseline)%>%
                                    mutate_all(~ as.numeric(factor(.)))
          
          } else if (stratify_var == 'mmse.status.baseline') {
            data_matrix <- subdf %>% select(hwd.ind, trueage, sex,
                                            ndvi.scale, pm25.scale, rh.scale, 
                                            adl.status, iadl.status)%>%
                                    mutate_all(~ as.numeric(factor(.)))
          }  else if (stratify_var == 'iadl.status') {
            data_matrix <- subdf %>% select(hwd.ind, trueage, sex,
                                            ndvi.scale, pm25.scale, rh.scale, 
                                            adl.status, mmse.status.baseline)%>%
                                    mutate_all(~ as.numeric(factor(.)))
          } else if (stratify_var == 'adl.status') {
            data_matrix <- subdf %>% select(hwd.ind, trueage, sex,
                                            ndvi.scale, pm25.scale, rh.scale, 
                                             mmse.status.baseline)%>%
                                    mutate_all(~ as.numeric(factor(.)))
        
        } else {
        data_matrix <- subdf %>% select(hwd.ind, trueage, sex,
                                            ndvi.scale, pm25.scale, rh.scale, 
                                            adl.status, iadl.status, mmse.status.baseline)%>%
                                 mutate_all(~ as.numeric(factor(.)))
        }
                                     
        
        
        pca_cor<-hetcor(data_matrix,ML=TRUE)
         
        # step3. conduct a PCA on the correlation matrix to generate eigenvectors
        my_pca <- princomp(pca_cor, n.comp = sum(my_pca$sdev^2 >= 1))
         
        # screen plot to find the elbow
        eig_df <- data.frame(Comp = 1:length(my_pca$sdev), Eigenvalue = my_pca$sdev^2)
       
         
        # step4. retain components with eighvalues â‰¥1 in the model. Then communality can be calculated as the sum of the square of all factor loadings
        my_loadings<-my_pca$loadings
        my_communality<-rowSums(my_loadings[,1:2]^2)
    
    
        
        subdf %>% filter(event.death == 1 & hwd.ind == 1) %>% summarise(event.exposed = n()) -> event.exposed; event.exposed = as.numeric(event.exposed)
        subdf %>% filter(event.death == 1 & hwd.ind == 0) %>% summarise(event.unexposed = n()) -> event.unexposed; event.unexposed = as.numeric(event.unexposed)
        
        subdf %>% filter(hwd.ind == 1) %>% summarise(pt.exposed = n()) -> pt.exposed; pt.exposed = as.numeric(pt.exposed)
        subdf %>% filter(hwd.ind == 0) %>% summarise(pt.unexposed = n()) -> pt.unexposed; pt.unexposed = as.numeric(pt.unexposed)
        
        
        # Calculate incidence rates
        ir_exposed <- event.exposed / pt.exposed
        ir_unexposed <- event.unexposed / pt.unexposed
        
        # Calculate Attributable Fraction
        af <- (ir_exposed - ir_unexposed) / ir_exposed
        
        # Calculate Population Attributable Fraction
        paf <- (af * hr) / (1 + af * (hr - 1))
        
        
        adjusted_af <- af * my_communality[1]  # Adjust for communality
        adjusted_paf <- (adjusted_af * hr) / (1 + adjusted_af * (hr - 1))
        # Print the calculated PAF
        cat(paste0(def, '_', level, "_adjusted PAF:"), adjusted_paf, "\n")
        
 
    
    #paf.list[[level]] = adjusted_paf

    #Define a function to calculate PAF
    calculate_paf <- function(data, indices, hr) {

        event.exposed <- sum(data$event.death[indices] == 1 & data$hwd.ind[indices] == 1)
        event.unexposed <- sum(data$event.death[indices] == 1 & data$hwd.ind[indices] == 0)
        pt.exposed <- sum(data$hwd.ind[indices] == 1)
        pt.unexposed <- sum(data$hwd.ind[indices] == 0)

        ir_exposed <- event.exposed / pt.exposed
        ir_unexposed <- event.unexposed / pt.unexposed
        af <- (ir_exposed - ir_unexposed) / ir_exposed
        adjusted_af <- af * my_communality[1]  # Adjust for communality
        adjusted_paf <- (adjusted_af * hr) / (1 + adjusted_af * (hr - 1))


    #return(adjusted_paf)
    }

  


    # Set the number of bootstrap replicates
    n_replicates <- 50
    
    # Perform bootstrap and calculate CI for PAF
    boot_results <- boot(data = df, statistic = calculate_paf, R = n_replicates, hr = hr)
    
    # Calculate the confidence interval using basic method
    ci <- boot.ci(boot_results, type = "basic", conf = 0.95)
    cat(paste0(def, '_', level, "_ci:"))
    print(ci)
    
    # Extract the CI lower and upper bounds
    ci_lower <- ci$basic[4]
    ci_upper <- ci$basic[5]
    
    result.paf = data.frame(definition = def, varname = stratify_var, var.level = level,
                            paf = adjusted_paf,
                            paf.conf.low = ci_lower, paf.conf.high = ci_upper)
    
    
    df.paf = rbind(df.paf, result.paf)
    
  }  
  
  return(df.paf)
}  



# list of every stratification variables  
var.list = subgroup_HRs$varname[1:52] %>% unique()
# store result dataframe
paf.df.list = list()
#var.list = var.list[c(18:20, 10, 17)]

# Apply the function to each stratification variable
for (var in var.list) {
  result <- getSubPAF(HW1_CMA_updated0615, "CMA", var, subgroup_HRs)
  paf.df.list[[var]] <- result
}
saveRDS(paf.df.list, 'HW1_paf_list.rds')
#getSubPAF(HW1_CMA_updated0615, 'CMA', 'iadl.status', subgroup_HRs)
  
```


```{r paf.list2}
paf.df.list2 = list()

for (var in var.list) {
  result <- getSubPAF(HW2_WMO_90th_1D_updated0615, "WMO_90th_1D", var, subgroup_HRs)
  paf.df.list2[[var]] <- result
}
saveRDS(paf.df.list2, 'HW2_paf_list.rds')
gc()
```



```{r paf.list3}
paf.df.list3 = list()

for (var in var.list) {
  result <- getSubPAF(HW3_WMO_90th_2D_updated0615, "WMO_90th_2D", var, subgroup_HRs)
  paf.df.list3[[var]] <- result
}
saveRDS(paf.df.list3, 'HW3_paf_list.rds')
gc()
```


```{r paf.list4}
paf.df.list4 = list()

for (var in var.list) {
  result <- getSubPAF(HW4_WMO_90th_3D_updated0615, "WMO_90th_3D", var, subgroup_HRs)
  paf.df.list4[[var]] <- result
}
saveRDS(paf.df.list4, 'HW4_paf_list.rds')
gc()
```


```{r paf.list5}
paf.df.list5 = list()

for (var in var.list) {
  result <- getSubPAF(HW5_WMO_95th_1D_updated0615, "WMO_95th_1D", var, subgroup_HRs)
  paf.df.list5[[var]] <- result
}
saveRDS(paf.df.list5, 'HW5_paf_list.rds')
gc()
```

```{r paf.list6}
paf.df.list6 = list()

for (var in var.list) {
  result <- getSubPAF(HW6_WMO_95th_2D_updated0615, "WMO_95th_2D", var, subgroup_HRs)
  paf.df.list6[[var]] <- result
}
saveRDS(paf.df.list6, 'HW6_paf_list.rds')
gc()
```


```{r paf.list7}
paf.df.list7 = list()

for (var in var.list) {
  result <- getSubPAF(HW7_WMO_95th_3D_updated0615, "WMO_95th_3D", var, subgroup_HRs)
  paf.df.list7[[var]] <- result
}
saveRDS(paf.df.list7, 'HW7_paf_list.rds')

```


```{r paf.list8}
paf.df.list8 = list()

for (var in var.list) {
  result <- getSubPAF(HW8_NOAA_10degree_1D_updated0615, "NOAA_10c_1D", var, subgroup_HRs)
  paf.df.list8[[var]] <- result
}
saveRDS(paf.df.list8, 'HW8_paf_list.rds')

```



```{r paf.list9}
paf.df.list9 = list()

for (var in var.list) {
  result <- getSubPAF(HW9_NOAA_10degree_2D_updated0615, "NOAA_10c_2D", var, subgroup_HRs)
  paf.df.list9[[var]] <- result
}
saveRDS(paf.df.list9, 'HW9_paf_list.rds')

```



```{r paf.list10}
paf.df.list10 = list()

for (var in var.list) {
  result <- getSubPAF(HW10_NOAA_10degree_3D_updated0615, "NOAA_10c_3D", var, subgroup_HRs)
  paf.df.list10[[var]] <- result
}
saveRDS(paf.df.list10, 'HW10_paf_list.rds')

```
